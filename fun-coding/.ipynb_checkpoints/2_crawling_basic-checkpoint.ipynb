{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eTvMYNhf8RAE"
   },
   "source": [
    "# 2. 크롤링(crawling) 이해 및 기본"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W8OPNMVR8Usa"
   },
   "source": [
    "## 2.2 BeautifulSoup 라이브러리를 활용한 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCtJjAwZ4uJ_"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6_UXCc_b82sq"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.2.1 `requests` 라이브러리를 활용한 HTML 페이지 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKBh-cF38GJf"
   },
   "outputs": [],
   "source": [
    "# res 객체에 HTML 데이터가 저장됨\n",
    "res = requests.get('https://news.v.daum.net/v/20170615203441266')\n",
    "\n",
    "# res.content로 데이터 추출 가능\n",
    "#print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Ojd9-MG8ojs"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.2.2 HTML 페이지 파싱\n",
    "\n",
    "- `BeautifulSoup(HTML데이터, 파싱방법)`\n",
    "  - HTML 문서를 파싱할 때는 파싱 방법으로 `'html.parser'` 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58JPRxKt8_-6"
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v3zm1BD49EyL"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.2.3 필요한 데이터 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3dNF9gCK9HYO",
    "outputId": "bf6e0241-ecff-4beb-d035-e4421b4c3bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>잔금대출에도 DTI 규제 적용 검토 | Daum 뉴스</title>\n"
     ]
    }
   ],
   "source": [
    "title = soup.find('title')\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ohScIDr9Ptr"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.2.4 필요한 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AYfenL9h9TpE",
    "outputId": "9cca3b29-e39c-47ca-d234-de217620625f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잔금대출에도 DTI 규제 적용 검토 | Daum 뉴스\n"
     ]
    }
   ],
   "source": [
    "print(title.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MIzd6LOR9V5a"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 2.3 BeautifulSoup 라이브러리 활용 다양한 예제\n",
    "\n",
    "- `find()`와 `find_all()` 메서드 사용법 이해\n",
    "  - `find()` : 가장 먼저 검색되는 태그 반환\n",
    "  - `find_all()` : 전체 태그 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X8Sd39ZA9qFc"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <h1 id='title'>[1]크롤링이란?</h1>;\n",
    "        <p class='cssstyle'>웹페이지에서 필요한 데이터를 추출하는 것</p>\n",
    "        <p id='body' align='center'>파이썬을 중심으로 다양한 웹크롤링 기술 발달</p>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "pwk9aKlY9vRh",
    "outputId": "15e71ed8-8aa1-4d65-9b5f-57b82832f981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"title\">[1]크롤링이란?</h1>\n",
      "[1]크롤링이란?\n",
      "[1]크롤링이란?\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 태그로 검색\n",
    "title_data = soup.find('h1')\n",
    "\n",
    "print(title_data)\n",
    "print(title_data.string)\n",
    "print(title_data.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k4cKA9dq99S6"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.3.1 `find()`\n",
    "\n",
    "- 가장 먼저 검색되는 태그 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "HNETZUzY-FL8",
    "outputId": "14b74dc7-37f9-4477-d2af-ac02e3d995e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"cssstyle\">웹페이지에서 필요한 데이터를 추출하는 것</p>\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "paragraph_data = soup.find('p')\n",
    "\n",
    "print(paragraph_data)\n",
    "print(paragraph_data.string)\n",
    "print(paragraph_data.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LdXRrHtP-Lah"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.3.2 `find(id='id값')`\n",
    "\n",
    "- 태그에 있는 id로 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "1W0B9HbI-TLy",
    "outputId": "a69881c0-4acf-47f1-a588-b76e480ace1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"title\">[1]크롤링이란?</h1>\n",
      "[1]크롤링이란?\n",
      "[1]크롤링이란?\n"
     ]
    }
   ],
   "source": [
    "title_data = soup.find(id='title')\n",
    "\n",
    "print(title_data)\n",
    "print(title_data.string)\n",
    "print(title_data.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8EW_cC9T-b5w"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.3.3 `find('태그명', class_='css 클래스명')`\n",
    "\n",
    "- HTML 태그와 CSS class를 활용해서 필요한 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "P8T-WYFm-tm6",
    "outputId": "21db5a79-1494-4dae-8013-6762451d75b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"cssstyle\">웹페이지에서 필요한 데이터를 추출하는 것</p>\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "paragraph_data = soup.find('p', class_='cssstyle')\n",
    "\n",
    "print(paragraph_data)\n",
    "print(paragraph_data.string)\n",
    "print(paragraph_data.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "2JNcz5pa-0_4",
    "outputId": "26123a88-1429-4d70-fac0-5f74dfa4ad8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"cssstyle\">웹페이지에서 필요한 데이터를 추출하는 것</p>\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "paragraph_data = soup.find('p', 'cssstyle')\n",
    "\n",
    "print(paragraph_data)\n",
    "print(paragraph_data.string)\n",
    "print(paragraph_data.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GUND9XV0-5CA"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.3.4 `find('태그명', attrs = {'속성키': '속성값'})`\n",
    "\n",
    "- HTML 태그와 태그에 있는 속성: 속성값을 활용해서 필요한 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "DrJabbe_A6IH",
    "outputId": "6120b36b-cfb0-4150-a7ce-1ffdae6afd46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p align=\"center\" id=\"body\">파이썬을 중심으로 다양한 웹크롤링 기술 발달</p>\n",
      "파이썬을 중심으로 다양한 웹크롤링 기술 발달\n",
      "파이썬을 중심으로 다양한 웹크롤링 기술 발달\n"
     ]
    }
   ],
   "source": [
    "paragraph_data = soup.find('p', attrs={'align': 'center'})\n",
    "\n",
    "print(paragraph_data)\n",
    "print(paragraph_data.string)\n",
    "print(paragraph_data.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dAQlVbq3A_71"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.3.5 `find_all()`\n",
    "\n",
    "- 관련된 모든 데이터를 리스트 형태로 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "HPlSh9mBBHFO",
    "outputId": "dda72c95-ccc1-4f66-a645-a05918e61d17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"cssstyle\">웹페이지에서 필요한 데이터를 추출하는 것</p>, <p align=\"center\" id=\"body\">파이썬을 중심으로 다양한 웹크롤링 기술 발달</p>]\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "파이썬을 중심으로 다양한 웹크롤링 기술 발달\n"
     ]
    }
   ],
   "source": [
    "paragraph_data = soup.find_all('p')\n",
    "\n",
    "print(paragraph_data)\n",
    "print(paragraph_data[0].get_text())\n",
    "print(paragraph_data[1].get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5mAUtGLHBOyM"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 2.4 BeautifulSoup 라이브러리 활용 string 검색 예제\n",
    "\n",
    "- 태그가 아닌 문자열 자체로 검색\n",
    "- 문자열, 정규표현식 등으로 검색 가능\n",
    "  - 문자열 검색의 경우 한 태그 내의 문자열과 exact matching인 것만 추출\n",
    "  - 이것이 의도한 경우가 아니라면 정규표현식 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hg3xWDIyFDsp"
   },
   "outputs": [],
   "source": [
    "res = requests.get('http://v.media.daum.net/v/20170518153405933')\n",
    "\n",
    "soup = BeautifulSoup(res.content, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4u0Xw-jWFbwm",
    "outputId": "4f0a8b87-128f-4bf0-efac-768b6709c38a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오대석']\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all(string='오대석'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KGHLehIDFex4",
    "outputId": "e0c408b5-2da4-4420-a6dd-3f92f2ad5ace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[이주의해시태그-#네이버-클로바]쑥쑥 크는 네이버 AI', '오대석']\n"
     ]
    }
   ],
   "source": [
    "print (soup.find_all(string=['[이주의해시태그-#네이버-클로바]쑥쑥 크는 네이버 AI', '오대석']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IlAfz-BOFmPM",
    "outputId": "6afcf98e-391d-4de5-8e43-971f08ab91c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all(string='AI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-TlCgMpGFqWM",
    "outputId": "83e265be-6969-423c-9c78-d576b25e8bd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[이주의해시태그-#네이버-클로바]쑥쑥 크는 네이버 AI | Daum 뉴스\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print(soup.find_all(string=re.compile('AI'))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lXZf6Kj7FvWk"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 2.5 연습 문제\n",
    "\n",
    "- 다음 사이트에서 링크가 되어 있는 모든 제목을 가져와서 출력\n",
    "- https://news.daum.net/digital/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xihLAA67GGL0"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://news.daum.net/digital/')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "colab_type": "code",
    "id": "i9T9UIa1GaJF",
    "outputId": "0d0522ac-cd79-4d7c-d5b0-be2d3347df7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7년 후 자율주행 선진국 추진..타다처럼 반발 부딪히면?\n",
      "인텔, 실시간 지름길 추천 스타트업 '무빗' 인수\n",
      "2027년 전국 주요 도로서 '완전 자율주행' 구현..사업 예타 통과\n",
      "코로나19로 웃은 넷플릭스, '뜨거운 감자'된 까닭은?\n",
      "넷플릭스 망사용료 무임승차 논란..공정위 \"면밀히 검토 중\"\n",
      "\"공짜망 안돼? 韓정부 상대로 페북도 이겼는데\"..'김앤장' 앞세운 넷플릭스\n",
      "반도체·신약개발 산파.. '방사광가속기' 입지 8일 발표\n",
      "충북도, 12년 만에 방사광가속기 유치 도전..\"준비된 재수생\"\n",
      "\"절치부심 12년을 기다렸다\"..충북, 방사광가속기 품을까\n",
      "딥페이크 적용 'GAN 알고리즘' 처리..모바일 기기서도 이미지 합성\n",
      "스포츠 기술로 '거리두기'하는 기업들\n",
      "인간 두뇌를 닮을 필요가 없어진 인공지능의 진화\n",
      "'디지털 위안화'도 있는데 '디지털 원화'는 없나?\n",
      "카페인, 피부에 양보하세요?..커피 밖 카페인\n",
      "애플워치, 병원에서 놓친 관상동맥질환 찾아냈다\n",
      "박수경 과기보좌관 어떤지 물어보니 \"아! 간사하겠다던 그 분\"\n",
      "갤럭시S20 공시지원금 대폭 올라.. 가격 10만원대까지 떨어지기도\n",
      "임영웅·아이유를 만화 캐릭터로..'selfie 2 waifu' 화제\n",
      "스마트폰 세계 1위 삼성전자, 인구 많은 '빅 마켓'에선 '끙끙'\n",
      "D램값 12% 폭등, 코로나에 '데이터 신경제' 속도 붙었다\n",
      "\"2년 약정 '빵집폰' 수두룩\"..스마트폰 대목 '불법보조금 전쟁'\n",
      "세계 첫 코로나 치료제 '렘데시비르'..치료비 500만원 넘을 듯\n",
      "LCD서 한국 밀어낸 중국, 이젠 대형 OLED다.. 기술자 빼내기 잰걸음\n",
      "반도체·신약개발 산파.. '방사광가속기' 입지 8일 발표\n",
      "\"2년 약정 '빵집폰' 수두룩\"..스마트폰 대목 '불법보조금 전쟁'\n",
      "'유리천장' 깬 40대 여성 과학자..박수경 청와대 과학기술보좌관\n"
     ]
    }
   ],
   "source": [
    "link_title = soup.find_all('a', attrs={'data-tiara-layer': 'article', 'class': 'link_txt'})\n",
    "\n",
    "for num in range(len(link_title)):\n",
    "    print(link_title[num].get_text().strip())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_crawling-basic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
